{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c06b18d9-355e-42a5-be36-0a58291e874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "#import os\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "648a81c8-2388-427a-95e1-6661f0b8c90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date         Open         High          Low        Close  \\\n",
      "0     1927-12-30    17.660000    17.660000    17.660000    17.660000   \n",
      "1     1928-01-03    17.760000    17.760000    17.760000    17.760000   \n",
      "2     1928-01-04    17.719999    17.719999    17.719999    17.719999   \n",
      "3     1928-01-05    17.549999    17.549999    17.549999    17.549999   \n",
      "4     1928-01-06    17.660000    17.660000    17.660000    17.660000   \n",
      "...          ...          ...          ...          ...          ...   \n",
      "23318 2020-10-29  3277.169922  3341.050049  3259.820068  3310.110107   \n",
      "23319 2020-10-30  3293.590088  3304.929932  3233.939941  3269.959961   \n",
      "23320 2020-11-02  3296.199951  3330.139893  3279.739990  3310.239990   \n",
      "23321 2020-11-03  3336.250000  3389.489990  3336.250000  3369.159912   \n",
      "23322 2020-11-04  3406.459961  3486.250000  3405.169922  3443.439941   \n",
      "\n",
      "         Adj Close      Volume  \n",
      "0        17.660000           0  \n",
      "1        17.760000           0  \n",
      "2        17.719999           0  \n",
      "3        17.549999           0  \n",
      "4        17.660000           0  \n",
      "...            ...         ...  \n",
      "23318  3310.110107  4903070000  \n",
      "23319  3269.959961  4840450000  \n",
      "23320  3310.239990  4310590000  \n",
      "23321  3369.159912  4220070000  \n",
      "23322  3443.439941  4783040000  \n",
      "\n",
      "[23323 rows x 7 columns]\n",
      "            Date        Close  Percent Change\n",
      "21851 2015-01-02  2058.199951       -0.033996\n",
      "21852 2015-01-05  2020.579956       -1.827811\n",
      "21853 2015-01-06  2002.609985       -0.889347\n",
      "21854 2015-01-07  2025.900024        1.162984\n",
      "21855 2015-01-08  2062.139893        1.788828\n",
      "...          ...          ...             ...\n",
      "23104 2019-12-24  3223.379883       -0.019545\n",
      "23105 2019-12-26  3239.909912        0.512817\n",
      "23106 2019-12-27  3240.020020        0.003398\n",
      "23107 2019-12-30  3221.290039       -0.578082\n",
      "23108 2019-12-31  3230.780029        0.294602\n",
      "\n",
      "[1258 rows x 3 columns]\n",
      "Overall average percent change: 0.03940767434417797\n",
      "             mean\n",
      "Quarter          \n",
      "1        0.062249\n",
      "2        0.036543\n",
      "3        0.028823\n",
      "4        0.030841\n",
      "Overall  0.039408\n",
      "P-value: 0.9649607643830633\n"
     ]
    }
   ],
   "source": [
    "sp_raw = pd.read_csv(\"C:\\\\Users\\\\SUKHJIT\\\\Downloads\\\\AMS325-RawProjectData\\\\SPX.csv\", parse_dates=['Date'])\n",
    "#parsed the date column into date format\n",
    "print(sp_raw)\n",
    "\n",
    "sp_proc = sp_raw.drop(columns=['Open','High','Low','Adj Close','Volume'])\n",
    "sp_proc[\"Percent Change\"] = sp_proc['Close'].pct_change()*100\n",
    "\n",
    "start = (np.where(sp_proc['Date'] == datetime.datetime(2015, 1, 2))[0])[0]\n",
    "end = (np.where(sp_proc['Date'] == datetime.datetime(2019, 12, 31))[0])[0]+1\n",
    "sp_proc = sp_proc[start:end]\n",
    "\n",
    "print(sp_proc)\n",
    "#Left with Close and Percent Change of Close Columns from 2010 to end of 2019\n",
    "\n",
    "#summary statistics of percent change column\n",
    "ave_spoverall = sp_proc['Percent Change'].describe()['mean']\n",
    "print('Overall average percent change:', sp_overall)\n",
    "\n",
    "#grouping by quarter\n",
    "sp_group = sp_proc\n",
    "sp_group['Quarter'] = sp_group['Date'].dt.quarter\n",
    "\n",
    "#stores data from different quarters to be used for testing later\n",
    "q1_sp = sp_group[sp_group['Quarter'] == 1]\n",
    "q2_sp = sp_group[sp_group['Quarter'] == 2]\n",
    "q3_sp = sp_group[sp_group['Quarter'] == 3]\n",
    "q4_sp = sp_group[sp_group['Quarter'] == 4]\n",
    "\n",
    "sp_group = sp_group.groupby('Quarter')['Percent Change'].agg(['mean'])\n",
    "sp_group.loc[\"Overall\"] = sp_overall\n",
    "print(sp_group)\n",
    "\n",
    "#statistical testing: anova\n",
    "from scipy import stats\n",
    "f_stat, p_value_sp = stats.f_oneway(q1_sp['Percent Change'], q2_sp['Percent Change'], q2_sp['Percent Change'], q4_sp['Percent Change'])\n",
    "print(\"P-value:\", p_value_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8331ac9d-dcd4-47e8-9881-20f0acdc024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Close  Percent Change  Quarter\n",
      "21851 2015-01-02  2058.199951       -0.033996        1\n",
      "21852 2015-01-05  2020.579956       -1.827811        1\n",
      "21853 2015-01-06  2002.609985       -0.889347        1\n",
      "21854 2015-01-07  2025.900024        1.162984        1\n",
      "21855 2015-01-08  2062.139893        1.788828        1\n",
      "...          ...          ...             ...      ...\n",
      "23104 2019-12-24  3223.379883       -0.019545        4\n",
      "23105 2019-12-26  3239.909912        0.512817        4\n",
      "23106 2019-12-27  3240.020020        0.003398        4\n",
      "23107 2019-12-30  3221.290039       -0.578082        4\n",
      "23108 2019-12-31  3230.780029        0.294602        4\n",
      "\n",
      "[1258 rows x 4 columns]\n",
      "226 230 477 481 728 732 979 983 1234 1238\n",
      "         Date        Close  Percent Change  Quarter\n",
      "0  2015-11-24  2089.139893        0.122200        4\n",
      "1  2015-11-25  2088.870117       -0.012913        4\n",
      "2  2015-11-27  2090.110107        0.059362        4\n",
      "3  2015-11-30  2080.409912       -0.464100        4\n",
      "4  2016-11-22  2202.939941        0.216543        4\n",
      "5  2016-11-23  2204.719971        0.080802        4\n",
      "6  2016-11-25  2213.350098        0.391439        4\n",
      "7  2016-11-28  2201.719971       -0.525454        4\n",
      "8  2017-11-21  2599.030029        0.654114        4\n",
      "9  2017-11-22  2597.080078       -0.075026        4\n",
      "10 2017-11-24  2602.419922        0.205610        4\n",
      "11 2017-11-27  2601.419922       -0.038426        4\n",
      "12 2018-11-20  2641.889893       -1.815124        4\n",
      "13 2018-11-21  2649.929932        0.304329        4\n",
      "14 2018-11-23  2632.560059       -0.655484        4\n",
      "15 2018-11-26  2673.449951        1.553237        4\n",
      "16 2019-11-26  3140.520020        0.219557        4\n",
      "17 2019-11-27  3153.629883        0.417442        4\n",
      "18 2019-11-29  3140.979980       -0.401122        4\n",
      "19 2019-12-02  3113.870117       -0.863102        4\n",
      "-0.03130581237522356 0.03940767434417797\n",
      "0.646226057887594\n"
     ]
    }
   ],
   "source": [
    "#this stores the overall average during this time period\n",
    "print(sp_proc)\n",
    "ave_sp_overall = sp_proc['Percent Change'].describe()['mean']\n",
    "\n",
    "#in this code, th15s corresponds to th = thanksgiving, 15 = year 2015, and s = start of 4-5 business day interval\n",
    "#the years change for each one to be included in the analysis\n",
    "#the dates listed in each statement are the start / end date to be included in the analysis\n",
    "th15s = (np.where(sp_proc['Date'] == datetime.datetime(2015, 11, 24))[0])[0]\n",
    "th15e = (np.where(sp_proc['Date'] == datetime.datetime(2015, 11, 30))[0])[0]+1\n",
    "th16s = (np.where(sp_proc['Date'] == datetime.datetime(2016, 11, 22))[0])[0]\n",
    "th16e = (np.where(sp_proc['Date'] == datetime.datetime(2016, 11, 28))[0])[0]+1\n",
    "th17s = (np.where(sp_proc['Date'] == datetime.datetime(2017, 11, 21))[0])[0]\n",
    "th17e = (np.where(sp_proc['Date'] == datetime.datetime(2017, 11, 27))[0])[0]+1\n",
    "th18s = (np.where(sp_proc['Date'] == datetime.datetime(2018, 11, 20))[0])[0]\n",
    "th18e = (np.where(sp_proc['Date'] == datetime.datetime(2018, 11, 26))[0])[0]+1\n",
    "th19s = (np.where(sp_proc['Date'] == datetime.datetime(2019, 11, 26))[0])[0]\n",
    "th19e = (np.where(sp_proc['Date'] == datetime.datetime(2019, 12, 2))[0])[0]+1\n",
    "print(th15s, th15e, th16s, th16e, th17s, th17e, th18s, th18e, th19s, th19e)\n",
    "\n",
    "#This concatenates the 5 selected intervals into one dataframe, sp_th, which contains the thanksgivings for this stock, S&P 500\n",
    "sp_th = pd.concat([sp_proc.iloc[th15s:th15e],sp_proc.iloc[th16s:th16e],sp_proc.iloc[th17s:th17e],sp_proc.iloc[th18s:th18e],sp_proc.iloc[th19s:th19e],], ignore_index=True)\n",
    "print(sp_th)\n",
    "\n",
    "#this line obtains the mean of the thanksgiving data\n",
    "ave_spth = sp_th['Percent Change'].describe()['mean']\n",
    "print(ave_spth, ave_sp_overall)\n",
    "\n",
    "#Outputs t-test for significance of difference from overall performance during this time\n",
    "#In this case, with a pvalue of 0.839, the answer is no signficant differents\n",
    "statistic, pvalue_spth = stats.ttest_ind(a=sp_proc['Percent Change'], b=sp_th['Percent Change'], equal_var=False)\n",
    "print(pvalue_spth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ee3ef295-b14a-4421-a846-6d42dfe55cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 32 279 283 531 536 783 788 1034 1039\n",
      "         Date        Close  Percent Change  Quarter\n",
      "0  2015-02-12  2088.479980        0.964451        1\n",
      "1  2015-02-13  2096.989990        0.407474        1\n",
      "2  2015-02-17  2100.340088        0.159757        1\n",
      "3  2015-02-18  2099.679932       -0.031431        1\n",
      "4  2016-02-11  1829.079956       -1.230116        1\n",
      "5  2016-02-12  1864.780029        1.951805        1\n",
      "6  2016-02-16  1895.579956        1.651665        1\n",
      "7  2016-02-17  1926.819946        1.648044        1\n",
      "8  2017-02-10  2316.100098        0.356605        1\n",
      "9  2017-02-13  2328.250000        0.524584        1\n",
      "10 2017-02-14  2337.580078        0.400734        1\n",
      "11 2017-02-15  2349.250000        0.499231        1\n",
      "12 2017-02-16  2347.219971       -0.086412        1\n",
      "13 2018-02-12  2656.000000        1.391458        1\n",
      "14 2018-02-13  2662.939941        0.261293        1\n",
      "15 2018-02-14  2698.629883        1.340246        1\n",
      "16 2018-02-15  2731.199951        1.206911        1\n",
      "17 2018-02-16  2732.219971        0.037347        1\n",
      "18 2019-02-12  2744.729980        1.289022        1\n",
      "19 2019-02-13  2753.030029        0.302399        1\n",
      "20 2019-02-14  2745.729980       -0.265164        1\n",
      "21 2019-02-15  2775.600098        1.087875        1\n",
      "22 2019-02-19  2779.760010        0.149874        1\n",
      "0.6094632253796882 0.03940767434417797\n",
      "0.0015364553411199033\n"
     ]
    }
   ],
   "source": [
    "#in this code, th15s corresponds to th = thanksgiving, 15 = year 2015, and s = start of 4-5 business day interval\n",
    "#the years change for each one to be included in the analysis\n",
    "#the dates listed in each statement are the start / end date to be included in the analysis\n",
    "va15s = (np.where(sp_proc['Date'] == datetime.datetime(2015, 2, 12))[0])[0]\n",
    "va15e = (np.where(sp_proc['Date'] == datetime.datetime(2015, 2, 18))[0])[0]+1\n",
    "va16s = (np.where(sp_proc['Date'] == datetime.datetime(2016, 2, 11))[0])[0]\n",
    "va16e = (np.where(sp_proc['Date'] == datetime.datetime(2016, 2, 17))[0])[0]+1\n",
    "va17s = (np.where(sp_proc['Date'] == datetime.datetime(2017, 2, 10))[0])[0]\n",
    "va17e = (np.where(sp_proc['Date'] == datetime.datetime(2017, 2, 16))[0])[0]+1\n",
    "va18s = (np.where(sp_proc['Date'] == datetime.datetime(2018, 2, 12))[0])[0]\n",
    "va18e = (np.where(sp_proc['Date'] == datetime.datetime(2018, 2, 16))[0])[0]+1\n",
    "va19s = (np.where(sp_proc['Date'] == datetime.datetime(2019, 2, 12))[0])[0]\n",
    "va19e = (np.where(sp_proc['Date'] == datetime.datetime(2019, 2, 19))[0])[0]+1\n",
    "print(va15s, va15e, va16s, va16e, va17s, va17e, va18s, va18e, va19s, va19e)\n",
    "\n",
    "#This concatenates the 5 selected intervals into one dataframe, sp_va, which contains the thanksgivings for vais stock, S&P 500\n",
    "sp_va = pd.concat([sp_proc.iloc[va15s:va15e],sp_proc.iloc[va16s:va16e],sp_proc.iloc[va17s:va17e],sp_proc.iloc[va18s:va18e],sp_proc.iloc[va19s:va19e],], ignore_index=True)\n",
    "print(sp_va)\n",
    "\n",
    "#this line obtains the mean of the thanksgiving data\n",
    "ave_spva = sp_va['Percent Change'].describe()['mean']\n",
    "print(ave_spva, ave_sp_overall)\n",
    "\n",
    "#Outputs t-test for significance of difference from overall performance during this time\n",
    "#In this case, with a pvalue of 0.0015, the answer is a signficant difference\n",
    "#the valentines day performance is higher\n",
    "statistic, pvalue_spva = stats.ttest_ind(a=sp_proc['Percent Change'], b=sp_va['Percent Change'], equal_var=False)\n",
    "print(pvalue_spva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "71ba0a2f-f346-482e-aac1-bc7739d31573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 128 376 380 628 632 880 884 1131 1135\n",
      "         Date        Close  Percent Change  Quarter\n",
      "0  2015-07-01  2077.419922        0.693604        3\n",
      "1  2015-07-02  2076.780029       -0.030802        3\n",
      "2  2015-07-06  2068.760010       -0.386176        3\n",
      "3  2015-07-07  2081.340088        0.608098        3\n",
      "4  2016-06-30  2098.860107        1.356504        2\n",
      "5  2016-07-01  2102.949951        0.194860        3\n",
      "6  2016-07-05  2088.550049       -0.684748        3\n",
      "7  2016-07-06  2099.729980        0.535296        3\n",
      "8  2017-06-30  2423.409912        0.153323        2\n",
      "9  2017-07-03  2429.010010        0.231083        3\n",
      "10 2017-07-05  2432.540039        0.145328        3\n",
      "11 2017-07-06  2409.750000       -0.936882        3\n",
      "12 2018-07-02  2726.709961        0.306796        3\n",
      "13 2018-07-03  2713.219971       -0.494735        3\n",
      "14 2018-07-05  2736.610107        0.862080        3\n",
      "15 2018-07-06  2759.820068        0.848128        3\n",
      "16 2019-07-02  2973.010010        0.292813        3\n",
      "17 2019-07-03  2995.820068        0.767238        3\n",
      "18 2019-07-05  2990.409912       -0.180590        3\n",
      "19 2019-07-08  2975.949951       -0.483544        3\n",
      "0.18988369867557583 0.03940767434417797\n",
      "0.2754183788692195\n"
     ]
    }
   ],
   "source": [
    "#in this code, th15s corresponds to th = thanksgiving, 15 = year 2015, and s = start of 4-5 business day interval\n",
    "#the years change for each one to be included in the analysis\n",
    "#the dates listed in each statement are the start / end date to be included in the analysis\n",
    "fj15s = (np.where(sp_proc['Date'] == datetime.datetime(2015, 7, 1))[0])[0]\n",
    "fj15e = (np.where(sp_proc['Date'] == datetime.datetime(2015, 7, 7))[0])[0]+1\n",
    "fj16s = (np.where(sp_proc['Date'] == datetime.datetime(2016, 6, 30))[0])[0]\n",
    "fj16e = (np.where(sp_proc['Date'] == datetime.datetime(2016, 7, 6))[0])[0]+1\n",
    "fj17s = (np.where(sp_proc['Date'] == datetime.datetime(2017, 6, 30))[0])[0]\n",
    "fj17e = (np.where(sp_proc['Date'] == datetime.datetime(2017, 7, 6))[0])[0]+1\n",
    "fj18s = (np.where(sp_proc['Date'] == datetime.datetime(2018, 7, 2))[0])[0]\n",
    "fj18e = (np.where(sp_proc['Date'] == datetime.datetime(2018, 7, 6))[0])[0]+1\n",
    "fj19s = (np.where(sp_proc['Date'] == datetime.datetime(2019, 7, 2))[0])[0]\n",
    "fj19e = (np.where(sp_proc['Date'] == datetime.datetime(2019, 7, 8))[0])[0]+1\n",
    "print(fj15s, fj15e, fj16s, fj16e, fj17s, fj17e, fj18s, fj18e, fj19s, fj19e)\n",
    "\n",
    "#This concatenates the 5 selected intervals into one dataframe, sp_fj, which contains the thanksgivings for vais stock, S&P 500\n",
    "sp_fj = pd.concat([sp_proc.iloc[fj15s:fj15e],sp_proc.iloc[fj16s:fj16e],sp_proc.iloc[fj17s:fj17e],sp_proc.iloc[fj18s:fj18e],sp_proc.iloc[fj19s:fj19e],], ignore_index=True)\n",
    "print(sp_fj)\n",
    "\n",
    "#this line obtains the mean of the thanksgiving data\n",
    "ave_spfj = sp_fj['Percent Change'].describe()['mean']\n",
    "print(ave_spfj, ave_sp_overall)\n",
    "\n",
    "#Outputs t-test for significance of difference from overall performance during this time\n",
    "#In this case, with a pvalue of 0.207, the conclusion is that the differences are insignificant\n",
    "statistic, pvalue_spfj = stats.ttest_ind(a=sp_proc['Percent Change'], b=sp_fj['Percent Change'], equal_var=False)\n",
    "print(pvalue_spfj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "89674513-7e7a-4c6a-bc8e-134387a20035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246 250 498 502 749 753 999 1004 1251 1256\n",
      "         Date        Close  Percent Change  Quarter\n",
      "0  2015-12-23  2064.290039        1.241807        4\n",
      "1  2015-12-24  2060.989990       -0.159864        4\n",
      "2  2015-12-28  2056.500000       -0.217856        4\n",
      "3  2015-12-29  2078.360107        1.062976        4\n",
      "4  2016-12-22  2260.959961       -0.186297        4\n",
      "5  2016-12-23  2263.790039        0.125172        4\n",
      "6  2016-12-27  2268.879883        0.224837        4\n",
      "7  2016-12-28  2249.919922       -0.835653        4\n",
      "8  2017-12-21  2684.570068        0.198566        4\n",
      "9  2017-12-22  2683.340088       -0.045817        4\n",
      "10 2017-12-26  2680.500000       -0.105842        4\n",
      "11 2017-12-27  2682.620117        0.079094        4\n",
      "12 2018-12-20  2467.419922       -1.577211        4\n",
      "13 2018-12-21  2416.620117       -2.058823        4\n",
      "14 2018-12-24  2351.100098       -2.711225        4\n",
      "15 2018-12-26  2467.699951        4.959374        4\n",
      "16 2018-12-27  2488.830078        0.856268        4\n",
      "17 2019-12-20  3221.219971        0.494478        4\n",
      "18 2019-12-23  3224.010010        0.086614        4\n",
      "19 2019-12-24  3223.379883       -0.019545        4\n",
      "20 2019-12-26  3239.909912        0.512817        4\n",
      "21 2019-12-27  3240.020020        0.003398        4\n",
      "0.08760316821666962 0.03940767434417797\n",
      "0.8768412202502154\n"
     ]
    }
   ],
   "source": [
    "#in this code, th15s corresponds to th = thanksgiving, 15 = year 2015, and s = start of 4-5 business day interval\n",
    "#the years change for each one to be included in the analysis\n",
    "#the dates listed in each statement are the start / end date to be included in the analysis\n",
    "ch15s = (np.where(sp_proc['Date'] == datetime.datetime(2015, 12, 23))[0])[0]\n",
    "ch15e = (np.where(sp_proc['Date'] == datetime.datetime(2015, 12, 29))[0])[0]+1\n",
    "ch16s = (np.where(sp_proc['Date'] == datetime.datetime(2016, 12, 22))[0])[0]\n",
    "ch16e = (np.where(sp_proc['Date'] == datetime.datetime(2016, 12, 28))[0])[0]+1\n",
    "ch17s = (np.where(sp_proc['Date'] == datetime.datetime(2017, 12, 21))[0])[0]\n",
    "ch17e = (np.where(sp_proc['Date'] == datetime.datetime(2017, 12, 27))[0])[0]+1\n",
    "ch18s = (np.where(sp_proc['Date'] == datetime.datetime(2018, 12, 20))[0])[0]\n",
    "ch18e = (np.where(sp_proc['Date'] == datetime.datetime(2018, 12, 27))[0])[0]+1\n",
    "ch19s = (np.where(sp_proc['Date'] == datetime.datetime(2019, 12, 20))[0])[0]\n",
    "ch19e = (np.where(sp_proc['Date'] == datetime.datetime(2019, 12, 27))[0])[0]+1\n",
    "print(ch15s, ch15e, ch16s, ch16e, ch17s, ch17e, ch18s, ch18e, ch19s, ch19e)\n",
    "\n",
    "#This concatenates the 5 selected intervals into one dataframe, sp_ch, which contains the thanksgivings for vais stock, S&P 500\n",
    "sp_ch = pd.concat([sp_proc.iloc[ch15s:ch15e],sp_proc.iloc[ch16s:ch16e],sp_proc.iloc[ch17s:ch17e],sp_proc.iloc[ch18s:ch18e],sp_proc.iloc[ch19s:ch19e],], ignore_index=True)\n",
    "print(sp_ch)\n",
    "\n",
    "#this line obtains the mean of the thanksgiving data\n",
    "ave_spch = sp_ch['Percent Change'].describe()['mean']\n",
    "print(ave_spch, ave_sp_overall)\n",
    "\n",
    "#Outputs t-test for significance of difference from overall performance during this time\n",
    "#In this case, with a pvalue of 0.786, the conclusion is that the differences are insignificant\n",
    "statistic, pvalue_spch = stats.ttest_ind(a=sp_proc['Percent Change'], b=sp_ch['Percent Change'], equal_var=False)\n",
    "print(pvalue_spch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa72630-99e6-4e2b-b851-0b701f4020db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Average Daily Percent Change</th>\n",
       "      <th>P-Value of Difference from Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valentines Day</td>\n",
       "      <td>0.609463</td>\n",
       "      <td>0.001536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fourth of July</td>\n",
       "      <td>0.189884</td>\n",
       "      <td>0.275418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanksgiving</td>\n",
       "      <td>-0.031306</td>\n",
       "      <td>0.646226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christmas</td>\n",
       "      <td>0.087603</td>\n",
       "      <td>0.876841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.039408</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Holiday  Average Daily Percent Change  \\\n",
       "0  Valentines Day                      0.609463   \n",
       "1  Fourth of July                      0.189884   \n",
       "2    Thanksgiving                     -0.031306   \n",
       "3       Christmas                      0.087603   \n",
       "4         Overall                      0.039408   \n",
       "\n",
       "   P-Value of Difference from Overall  \n",
       "0                            0.001536  \n",
       "1                            0.275418  \n",
       "2                            0.646226  \n",
       "3                            0.876841  \n",
       "4                                 NaN  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_summary = pd.DataFrame({'Holiday': ['Valentines Day', 'Fourth of July', 'Thanksgiving', 'Christmas', 'Overall'], \n",
    "              'Average Daily Percent Change': [ave_spva, ave_spfj, ave_spth, ave_spch, ave_spoverall], 'P-Value of Difference from Overall':[pvalue_spva, pvalue_spfj, pvalue_spth, pvalue_spch, None]})\n",
    "\n",
    "ax = sp_summary.plot.bar(x='Holiday', y='Average Daily Percent Change', rot=0)\n",
    "ax = sp_summary.plot.bar(x='Holiday', y='P-Value of Difference from Overall', rot=0)\n",
    "\n",
    "sp_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
